{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNA MLP Imag ANIMALES.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2OvlxnFIsNyT","colab_type":"text"},"source":["# Demo RNA Multi-Perceptrón Backpropagation usando Keras para procesar imágenes e identificar TIPOS de ANIMALES"]},{"cell_type":"markdown","metadata":{"id":"WGdqrNAvsWiF","colab_type":"text"},"source":["1) Cargar librerías:"]},{"cell_type":"code","metadata":{"id":"gcVLfyLKsaCj","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Librerías a usar\n","import keras\n","from keras.layers import Input, Dense\n","from keras.models import Model\n","from keras.utils import plot_model\n","\n","from keras.utils import np_utils\n","\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from PIL import Image\n","\n","from  sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"Librerías cargadas\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xXate9UMmhDA","colab_type":"text"},"source":["2) Definir los parámetros:"]},{"cell_type":"code","metadata":{"id":"_JT7y1jKmrD9","colab_type":"code","cellView":"form","colab":{}},"source":["## selección de los parámetros \n","\n","# \n","#@markdown ### Parámetros de imágenes:\n","imagen_largo_ancho = 20 #@param {type:\"integer\"}\n","imagen_color = True #@param {type:\"boolean\"}\n","imagen_usar_generadas_data_augmentation = True #@param {type:\"boolean\"}\n","\n","#@markdown ### Parámetros de la red:\n","rna_cant_neuronas_capas_ocultas = '240, 60, 12' #@param {type:\"string\"}\n","rna_tipo_capa_salida = 'softmax-MultiClase' #@param [\"lineal-Numero\", \"softmax-MultiClase\"]\n","rna_cant_epocas_entrenamiento = 300 #@param {type:\"integer\"}\n","\n","\n","## aplicación de los parámetros elegidos\n","\n","# tamaño de las imágenes\n","if imagen_largo_ancho<=10:\n","  imagen_largo_ancho = 10\n","IMAGE_SHAPE = (imagen_largo_ancho, imagen_largo_ancho, (3 if imagen_color else 1))\n","\n","# indica si se usan las imágenes generadas por data augmentation\n","usarDA = imagen_usar_generadas_data_augmentation\n","\n","# define tamaño de datos de entrada \n","num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n","\n","# cantidad de neuronas ocultas \n","##hidden_layers = [ num_inputs//5, num_inputs//20, num_inputs//100 ]\n","hidden_layers = []\n","for val in rna_cant_neuronas_capas_ocultas.split(','):\n","  hidden_layers.append( int(val) )\n","\n","# define si el tipo de capa de salida es softmax( True )  o lineal ( False )\n","# esto implica también cambiar cómo se codifican los valores de las clases a usar\n","tipo_output_softMax = (rna_tipo_capa_salida[:7] == 'softmax')\n","\n","# cantidad de épocas del entrenamiento\n","cantEpocas = (100 if rna_cant_epocas_entrenamiento<1 else rna_cant_epocas_entrenamiento)\n","\n","print (\"Tamaño Imagen: \", IMAGE_SHAPE)\n","print(\"Configuración de RNA MLP Backpropagation definida: [\", num_inputs, hidden_layers, (\"Softmax\" if tipo_output_softMax else \"Dense[1] \"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Rm33ZPNnBpE","colab_type":"text"},"source":["3) Montar el Drive:"]},{"cell_type":"code","metadata":{"id":"ysaIl300nDud","colab_type":"code","cellView":"form","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# directorio local en Google Drive\n","path = 'gdrive/My Drive/IA/demo ANIMALES/imagenes' #@param {type:\"string\"}\n","path_entrenamiento = '/train'  #@param {type:\"string\"}\n","path_prueba = '/test'  #@param {type:\"string\"}\n","\n","imagPath_train = path + path_entrenamiento\n","imagPath_test = path + path_prueba"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sDkaUtZ6nG8l","colab_type":"text"},"source":["4) Cargar imágenes para entrenar el modelo:"]},{"cell_type":"code","metadata":{"id":"uYz8mV4SnJ4O","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Cargar imágenes\n","# define función para cargar las imágenes\n","def cargarImagenes(imagPath):\n","  classes_ori = [] \n","  images_ori = []\n","  esDA_ori = []\n","\n","  all_dirs = os.listdir( imagPath )\n","  for each_dir in all_dirs:\n","\n","      auxiPath = imagPath + '/' + each_dir \n","      imagFN  = os.listdir( auxiPath )\n","      for each_imagFN in imagFN:\n","\n","            esImagDA = (each_imagFN[:2] == 'da')\n","            \n","            if usarDA or (not esImagDA): \n","                \n","                # abre la imagen\n","                imag = Image.open(auxiPath + \"/\" + each_imagFN)\n","                \n","                # ajusta el tamaño\n","                if IMAGE_SHAPE[2]==1:              \n","                  tipoImage = 'L'\n","                else:                \n","                  tipoImage = 'RGB'\n","                imag = imag.convert(tipoImage)\n","                imag = imag.resize((IMAGE_SHAPE[0], IMAGE_SHAPE[1]), Image.ANTIALIAS)          \n","                \n","                # transforma a un vector de nros\n","                arImag = np.array(imag)\n","                \n","                # agrega a los vectores\n","                classes_ori.append( each_dir )\n","                images_ori.append( arImag )\n","                esDA_ori.append( esImagDA )\n","\n","  return classes_ori, images_ori, esDA_ori, tipoImage\n","\n","# carga las imagenes de entrenamiento\n","classes_train, images_train, esDAimag_train, tipoImage_train = cargarImagenes(imagPath_train)\n","print(\"> Para Entrenamiento: \")\n","print(\"- Clases cargadas: \", len(classes_train))\n","print(\"- Imágenes cargadas: \", len(classes_train))\n","\n","if len(classes_train)>0:\n","  print(\"- Ejemplo \", classes_train[0], \" \", images_train[0].shape, \": \")\n","  display( Image.fromarray(images_train[0], tipoImage_train) )\n","\n","# carga las imagenes de prueba\n","classes_test, images_test, esDAimag_test, tipoImage_test = cargarImagenes(imagPath_test)\n","print(\"\\n\\n> Para Prueba: \")\n","print(\"- Clases cargadas: \", len(classes_test))\n","print(\"- Imágenes cargadas: \", len(images_test))\n","\n","if len(classes_test)>0:\n","  print(\"- Ejemplo \", classes_test[0], \" \", images_test[0].shape, \": \")\n","  display( Image.fromarray(images_test[0], tipoImage_test) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPPvnkjTnTQN","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Preparar imágenes\n","# define función auxiliar para mostrar imágenes preparadas\n","def plot_image(imag):\n","  if IMAGE_SHAPE[2]==1:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8))\n","    plt.gray()\n","  else:\n","    plt.imshow((imag*255).reshape(IMAGE_SHAPE).astype(np.uint8))\n","  plt.axis(\"off\")  \n","\n","# define función auxiliar para preparar la lista de imágenes a procesar\n","def prepare_imageList(imagList):    \n","  auxiAr = np.array(imagList).astype('float32') / 255.\n","  auxiAr = auxiAr.reshape((len(auxiAr), num_inputs))  \n","  return np.array(auxiAr)\n","\n","# define función auxiliar para preparar lista de clases \n","def prepare_clasesList(classesList, dictMapeo=None):\n","  if dictMapeo==None:\n","    # genera diccionario de mapeo\n","    auxDict = list(set(classesList))\n","    dictMapeo = dict( zip( auxDict, range(len(auxDict)) ) )\n","  # realiza el mapeo\n","  y = []\n","  for cl in classesList:\n","      y.append( dictMapeo[cl] )\n","  # convierte valores numéricos a columnas de vakores binarios (i.e. one hot encoded)\n","  dummy_y = np_utils.to_categorical(y)\n","  # devuelve\n","  return np.array(y), np.array(dummy_y), dictMapeo\n","\n","# define vector auxiliar de datos de entrada para usar en el entrenamiento y prueba\n","x_train = prepare_imageList(images_train)\n","x_test = prepare_imageList(images_test)\n","\n","# define vector auxiliar de datos de salida para usar en el entrenamiento y prueba\n","# también usa esta información para determinar la cantida de neuronas de salida\n","y_train, y_trainEnc, dictMapeo = prepare_clasesList(classes_train)\n","y_test, y_testEnc,_ = prepare_clasesList(classes_test, dictMapeo)\n","\n","# genera diccionario auxiliar para poder convertir de ID de clase a nombre de clase\n","clases_map = [ x for x,y in dictMapeo.items() ]\n","\n","print(\"> Para Entrenamiento: \")\n","print(\" - x_train (cant ejemplos, datos entrada): \", x_train.shape)\n","if tipo_output_softMax:\n","  print(\" - y_trainEnc (cant): \", len(y_trainEnc))\n","else:\n","  print(\" - y_train (cant): \", len(y_train))\n","print(\"\\n\\n> Para Prueba: \")\n","print(\" - x_test (cant ejemplos, datos entrada): \", x_test.shape)\n","if tipo_output_softMax:\n","  print(\" - y_testEnc (cant): \", len(y_testEnc))\n","else:\n","  print(\" - y_test (cant): \", len(y_test))\n","print(\"\\n\\n> Para Ambos: \")\n","print(\" - dictMapeo: \", dictMapeo)\n","print(\" - clases_map: \", clases_map)\n","if len(y_train)>0:\n","  print(\"\\n - Imagen reconstruida de \", clases_map[y_train[0]],  \"(\", y_train[0], \" / \", y_trainEnc[0], \")\")\n","  plot_image(x_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wvooB4Gws7ua","colab_type":"text"},"source":["5) Establecer el modelo para la RNA:"]},{"cell_type":"code","metadata":{"id":"_MlYyhEutC_O","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Establecer modelo\n","\n","# define la arquitectura de capas teniendo en cuenta la definición dada anteriomente\n","input_img_Lay = Input(shape=(num_inputs,), name='input_img') # capa de entrada\n","eachLay = input_img_Lay\n","auxName = 'hidd_'\n","auxId = 1 \n","for num_hid in hidden_layers:  \n","    \n","    # agrega la capa oculta\n","    auxlayerName = auxName+str(auxId)\n","    auxId = auxId + 1\n","    eachLay = Dense(num_hid, name=auxlayerName)(eachLay) # capas ocultas\n","\n","# agrega capa de salida\n","if tipo_output_softMax:\n","    # se genera una capa softmax\n","    output_img_Lay = Dense(units = len(dictMapeo), activation='softmax', name='output')(eachLay) # capa de salida\n","else:\n","    # se genera una capa lineal con una salida numérica\n","    output_img_Lay = Dense(1, activation=None, name='output')(eachLay) # capa de salida\n","\n","# genera el modelo RNA MLP Backpropagation\n","model = Model(input_img_Lay, output_img_Lay, name='RNA')\n","#model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n","if tipo_output_softMax:\n","    # utiliza un loss de multiple clases\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","else:\n","    # utiliza un loss de valor numérico\n","    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n","\n","print(\"Modelo creado con \", len(model.layers), \" capas:\")\n","model.summary()\n","print(\"\\n\")\n","plot_model(model, show_layer_names=True, show_shapes=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBtXyyXCtjDc","colab_type":"text"},"source":["6) Entrenar el modelo de la RNA:"]},{"cell_type":"code","metadata":{"id":"21pQvmtCtn-T","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Entrenar\n","# lleva a cabo el entrenamiento\n","model.fit(x_train, \n","          (y_trainEnc if tipo_output_softMax else y_train),\n","          epochs = cantEpocas, \n","          batch_size = 15) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzmLDXuUHkdf","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Probar red entrenada con datos de entrenamiento\n","# función auxiliar para probar el modelo entrenado en detalle\n","def probarModelo(x, y, esDAimag, clases_map):\n","\n","    # procesa las imágenes de prueba con el modelo \n","    predClass = model.predict(x)\n","\n","    # muestra los resultados con las imágenes \n","    umbralClas = 0.5\n","    classPreds = []\n","    classReal = []\n","    for i in range(len(x)):\n","\n","        # asigna el nombre de la clase real\n","        clReal = clases_map[ y[i] ] \n","\n","        # determina la clase predecida\n","        if tipo_output_softMax:\n","            ## determina clase predecida de acuerdo a la que tiene mayor valor\n","            idclPred = int( np.argmax(predClass[i], axis=0) )\n","            idclPredRnd = idclPred\n","        else:\n","            ## determina clase predecida de acuerdo al umbral de clasificación\n","            idclPred = predClass[i][0]       \n","            idclPredRnd = int(idclPred)\n","            if (idclPred - idclPredRnd)>0.5 and (idclPredRnd+1)<len(clases_map):\n","                    idclPredRnd = idclPredRnd + 1\n","\n","        # asigna el nombre de la clase predecida\n","        if idclPredRnd<0 or idclPredRnd>=len(clases_map):\n","            clPred = \"CLASE \" + str(idclPredRnd) + \" INVÁLIDA!\"\n","        else:      \n","            clPred = clases_map[ idclPredRnd ]\n","\n","        # agrega a vevtores auxiliares\n","        classReal.append( clReal )\n","        classPreds.append( clPred )\n","\n","        # sólo muestra las imágenes no generadas por DA\n","        if not esDAimag[i]:\n","          strTitulo = 'Real: ' + clReal + ' / RNA: ' \n","          strTitulo = strTitulo + clPred + ' (' + str( idclPred ) +')'    \n","\n","          # muestra comparación con la imagen\n","          fig = plt.figure()\n","          fig.suptitle( strTitulo )\n","          ax1 = fig.add_subplot(121)\n","          plot_image( x[i] )\n","          \n","          plt.tight_layout()\n","          fig = plt.gcf()\n","\n","    # muestra reporte de clasificación\n","    print(\"\\n Reporte de Clasificación: \")\n","    print(classification_report(classReal, classPreds))\n","\n","    # muestra matriz de confusion\n","    print('\\nMatriz de Confusión: ')\n","    cm = confusion_matrix(classReal, classPreds, labels=clases_map)\n","    cmtx = pd.DataFrame(\n","        cm, \n","        index=['r:{:}'.format(x) for x in clases_map], \n","        columns=['p:{:}'.format(x) for x in clases_map]\n","      )\n","    print(cmtx)\n","    print(\"\\n\")\n","\n","    print(\"\\n>Resultados: \")\n","\n","\n","# prueba con los datos de prueba\n","print(\"*** Resultados con datos de Entrenamiento: \")\n","probarModelo(x_train, y_train, esDAimag_train, clases_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yh-6p2xDtrUU","colab_type":"text"},"source":["7) Evaluar el modelo de la RNA entrenado usando las imágenes de prueba:"]},{"cell_type":"code","metadata":{"id":"A15K-9TRtq7U","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Probar red entrenada con datos de prueba\n"," # evalua al modelo entrenado\n","resEval = model.evaluate(x_test, (y_testEnc if tipo_output_softMax else y_test),)\n","print(\"\\n>Evaluación del Modelo: \")\n","print(\"    - Error: \", resEval[0])\n","print(\"    - Exactitud: \", resEval[1]*100)\n","print(\"\\n\")\n","\n","# prueba con los datos de entrenamiento\n","print(\"\\n\\n*** Resultados con datos de Prueba: \")\n","probarModelo(x_test, y_test, esDAimag_test, clases_map)"],"execution_count":null,"outputs":[]}]}
